@article{vaswani2017attention,
  title={Attention Is All You Need},
  author={Vaswani, Ashish and Shazeer, Noam and Parmar, Niki and Uszkoreit, Jakob and Jones, Llion and Gomez, Aidan N and Kaiser, ≈Åukasz and Polosukhin, Illia},
  journal={Advances in Neural Information Processing Systems},
  volume={30},
  pages={5998--6008},
  year={2017}
}

@article{brown2020language,
  title={Language Models are Few-Shot Learners},
  author={Brown, Tom B and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, G and Askell, Amanda and others},
  journal={Advances in Neural Information Processing Systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}

@article{ouyang2022training,
  title={Training language models to follow instructions with human feedback},
  author={Ouyang, Long and Wu, Jeff and Jiang, Xu and Almeida, Diogo and Wainwright, Carroll and Mishkin, Pamela and Zhang, Chong and Agarwal, Sandhini and Slama, Katarina and Ray, Alex and others},
  journal={Advances in Neural Information Processing Systems},
  volume={35},
  pages={27730--27744},
  year={2022}
}

@article{leike2018scalable,
  title={Scalable agent alignment via reward modeling: a research agenda},
  author={Leike, Jan and Krakovna, Victoria and Orseau, Laurent and Barnes, Rowan and Schneider, Jonas and Everitt, Tom and Lefrancq, Anastassia and Bolander, Thomas and Irving, Geoffrey and Legg, Shane},
  journal={arXiv preprint arXiv:1811.07871},
  year={2018}
}

@article{ganguli2022predictability,
  title={Predictability and surprise in large generative models},
  author={Ganguli, Deep and Askell, Amanda and Bai, Yuntao and Bowman, Samuel R and Carlini, Nicholas and Cobbe, Karl and Dai, Andrew and DasSarma, Nisanth and Dyer, Chris and Humeau, Samuel and others},
  journal={arXiv preprint arXiv:2202.07785},
  year={2022}
}


